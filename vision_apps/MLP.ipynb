{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Basic code for 2 Hidden Layer Netowork for MNIST sample set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Locations\n",
    "train_path = './data/mnist_example/digitstrain.csv'\n",
    "val_path = './data/mnist_example/digitsvalid.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2999,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "X_train = np.asarray(train_data.values[:,:784])\n",
    "Y_train = np.asarray(train_data.values[:,784])\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 784\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Making the TF Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, n_inputs], name = \"X\")\n",
    "y = tf.placeholder(tf.int64, shape = [None], name = \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Method-1 : Create your own funtion\n",
    "def neuron_layer(X, n_neurons, name, activation = None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs + n_neurons)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev = stddev)\n",
    "        W = tf.Variable(init, name = \"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name = \"bias\")\n",
    "        Z = tf.matmul(X,W) +b\n",
    "        if activation == None:\n",
    "            return Z\n",
    "        else:\n",
    "            return activation(Z)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name = \"hidden1\", activation = tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name= \"hidden2\", activation = tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name = \"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method -2: Use tf.layers.dense.\n",
    "\n",
    "with tf.name_scope(\"dnn2\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name = \"hidden1\", activation =tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name = \"hidden2\", activation = tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name= \"logits\", activation=tf.nn.elu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y,\n",
    "                                                             logits = logits)\n",
    "    loss = tf.reduce_mean(xentropy, name = \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate= learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Execution of TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 , Validation Accuracy : 0.3103103\n",
      "Epoch : 1 , Validation Accuracy : 0.46346346\n",
      "Epoch : 2 , Validation Accuracy : 0.57657659\n",
      "Epoch : 3 , Validation Accuracy : 0.66266268\n",
      "Epoch : 4 , Validation Accuracy : 0.71671671\n",
      "Epoch : 5 , Validation Accuracy : 0.75675678\n",
      "Epoch : 6 , Validation Accuracy : 0.77277279\n",
      "Epoch : 7 , Validation Accuracy : 0.7897898\n",
      "Epoch : 8 , Validation Accuracy : 0.81381381\n",
      "Epoch : 9 , Validation Accuracy : 0.82882881\n",
      "Epoch : 10 , Validation Accuracy : 0.82782781\n",
      "Epoch : 11 , Validation Accuracy : 0.83683681\n",
      "Epoch : 12 , Validation Accuracy : 0.83583581\n",
      "Epoch : 13 , Validation Accuracy : 0.84184182\n",
      "Epoch : 14 , Validation Accuracy : 0.84184182\n",
      "Epoch : 15 , Validation Accuracy : 0.84684682\n",
      "Epoch : 16 , Validation Accuracy : 0.85185188\n",
      "Epoch : 17 , Validation Accuracy : 0.85685688\n",
      "Epoch : 18 , Validation Accuracy : 0.86286288\n",
      "Epoch : 19 , Validation Accuracy : 0.86786789\n",
      "Epoch : 20 , Validation Accuracy : 0.87187189\n",
      "Epoch : 21 , Validation Accuracy : 0.87087089\n",
      "Epoch : 22 , Validation Accuracy : 0.87587589\n",
      "Epoch : 23 , Validation Accuracy : 0.87287289\n",
      "Epoch : 24 , Validation Accuracy : 0.88088089\n",
      "Epoch : 25 , Validation Accuracy : 0.87987989\n",
      "Epoch : 26 , Validation Accuracy : 0.88188189\n",
      "Epoch : 27 , Validation Accuracy : 0.87987989\n",
      "Epoch : 28 , Validation Accuracy : 0.88088089\n",
      "Epoch : 29 , Validation Accuracy : 0.88488489\n",
      "Epoch : 30 , Validation Accuracy : 0.88388389\n",
      "Epoch : 31 , Validation Accuracy : 0.88488489\n",
      "Epoch : 32 , Validation Accuracy : 0.88588589\n",
      "Epoch : 33 , Validation Accuracy : 0.88588589\n",
      "Epoch : 34 , Validation Accuracy : 0.88588589\n",
      "Epoch : 35 , Validation Accuracy : 0.8888889\n",
      "Epoch : 36 , Validation Accuracy : 0.8888889\n",
      "Epoch : 37 , Validation Accuracy : 0.8898899\n",
      "Epoch : 38 , Validation Accuracy : 0.8888889\n",
      "Epoch : 39 , Validation Accuracy : 0.8918919\n",
      "Epoch : 40 , Validation Accuracy : 0.8898899\n",
      "Epoch : 41 , Validation Accuracy : 0.8888889\n",
      "Epoch : 42 , Validation Accuracy : 0.8908909\n",
      "Epoch : 43 , Validation Accuracy : 0.8898899\n",
      "Epoch : 44 , Validation Accuracy : 0.8918919\n",
      "Epoch : 45 , Validation Accuracy : 0.8898899\n",
      "Epoch : 46 , Validation Accuracy : 0.8928929\n",
      "Epoch : 47 , Validation Accuracy : 0.8898899\n",
      "Epoch : 48 , Validation Accuracy : 0.8928929\n",
      "Epoch : 49 , Validation Accuracy : 0.8898899\n",
      "Epoch : 50 , Validation Accuracy : 0.8888889\n",
      "Epoch : 51 , Validation Accuracy : 0.8888889\n",
      "Epoch : 52 , Validation Accuracy : 0.8898899\n",
      "Epoch : 53 , Validation Accuracy : 0.8918919\n",
      "Epoch : 54 , Validation Accuracy : 0.8908909\n",
      "Epoch : 55 , Validation Accuracy : 0.8928929\n",
      "Epoch : 56 , Validation Accuracy : 0.8918919\n",
      "Epoch : 57 , Validation Accuracy : 0.8918919\n",
      "Epoch : 58 , Validation Accuracy : 0.8958959\n",
      "Epoch : 59 , Validation Accuracy : 0.8948949\n",
      "Epoch : 60 , Validation Accuracy : 0.8908909\n",
      "Epoch : 61 , Validation Accuracy : 0.8938939\n",
      "Epoch : 62 , Validation Accuracy : 0.8908909\n",
      "Epoch : 63 , Validation Accuracy : 0.8918919\n",
      "Epoch : 64 , Validation Accuracy : 0.8928929\n",
      "Epoch : 65 , Validation Accuracy : 0.8938939\n",
      "Epoch : 66 , Validation Accuracy : 0.8968969\n",
      "Epoch : 67 , Validation Accuracy : 0.8938939\n",
      "Epoch : 68 , Validation Accuracy : 0.8948949\n",
      "Epoch : 69 , Validation Accuracy : 0.8948949\n",
      "Epoch : 70 , Validation Accuracy : 0.8958959\n",
      "Epoch : 71 , Validation Accuracy : 0.8938939\n",
      "Epoch : 72 , Validation Accuracy : 0.8958959\n",
      "Epoch : 73 , Validation Accuracy : 0.8948949\n",
      "Epoch : 74 , Validation Accuracy : 0.8978979\n",
      "Epoch : 75 , Validation Accuracy : 0.8988989\n",
      "Epoch : 76 , Validation Accuracy : 0.8968969\n",
      "Epoch : 77 , Validation Accuracy : 0.8948949\n",
      "Epoch : 78 , Validation Accuracy : 0.8978979\n",
      "Epoch : 79 , Validation Accuracy : 0.8968969\n",
      "Epoch : 80 , Validation Accuracy : 0.8978979\n",
      "Epoch : 81 , Validation Accuracy : 0.8958959\n",
      "Epoch : 82 , Validation Accuracy : 0.8978979\n",
      "Epoch : 83 , Validation Accuracy : 0.8958959\n",
      "Epoch : 84 , Validation Accuracy : 0.8988989\n",
      "Epoch : 85 , Validation Accuracy : 0.8978979\n",
      "Epoch : 86 , Validation Accuracy : 0.8968969\n",
      "Epoch : 87 , Validation Accuracy : 0.8998999\n",
      "Epoch : 88 , Validation Accuracy : 0.8978979\n",
      "Epoch : 89 , Validation Accuracy : 0.8978979\n",
      "Epoch : 90 , Validation Accuracy : 0.8988989\n",
      "Epoch : 91 , Validation Accuracy : 0.8978979\n",
      "Epoch : 92 , Validation Accuracy : 0.8978979\n",
      "Epoch : 93 , Validation Accuracy : 0.9009009\n",
      "Epoch : 94 , Validation Accuracy : 0.8988989\n",
      "Epoch : 95 , Validation Accuracy : 0.8988989\n",
      "Epoch : 96 , Validation Accuracy : 0.8988989\n",
      "Epoch : 97 , Validation Accuracy : 0.9009009\n",
      "Epoch : 98 , Validation Accuracy : 0.8978979\n",
      "Epoch : 99 , Validation Accuracy : 0.8998999\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "val_data = pd.read_csv(val_path)\n",
    "test = val_data.values \n",
    "train_data = train_data.values\n",
    "np.random.shuffle(train_data)\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        np.random.shuffle(train_data)\n",
    "        ind = 0\n",
    "        while ind < train_data.shape[0]:\n",
    "            X_batch = train_data[ind:ind+batch_size, :784]\n",
    "            y_batch = train_data[ind:ind+batch_size,784]\n",
    "            sess.run(training_op, feed_dict = {X : X_batch, y : y_batch})\n",
    "            ind += batch_size\n",
    "        acc_val = accuracy.eval(feed_dict = {X : test[:,:784], y : test[:,784]})\n",
    "        print(\"Epoch : {!r} , Validation Accuracy : {!r}\".format(epoch, acc_val))\n",
    "        #print ( \"\" % epoch, acc_val)\n",
    "    save_path = saver.save(sess, './trained_models/MLP.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
